2025-09-10 17:57:54,822 - INFO - Epoch 001 Batch 0100/1563 - Loss: 2.2049
2025-09-10 17:57:56,405 - INFO - Epoch 001 Batch 0200/1563 - Loss: 2.2080
2025-09-10 17:57:57,993 - INFO - Epoch 001 Batch 0300/1563 - Loss: 1.8050
2025-09-10 17:57:59,603 - INFO - Epoch 001 Batch 0400/1563 - Loss: 2.0117
2025-09-10 17:58:01,230 - INFO - Epoch 001 Batch 0500/1563 - Loss: 1.7738
2025-09-10 17:58:02,866 - INFO - Epoch 001 Batch 0600/1563 - Loss: 2.0100
2025-09-10 17:58:04,498 - INFO - Epoch 001 Batch 0700/1563 - Loss: 1.8035
2025-09-10 17:58:06,139 - INFO - Epoch 001 Batch 0800/1563 - Loss: 1.6759
2025-09-10 17:58:07,765 - INFO - Epoch 001 Batch 0900/1563 - Loss: 1.5813
2025-09-10 17:58:09,391 - INFO - Epoch 001 Batch 1000/1563 - Loss: 1.6793
2025-09-10 17:58:10,967 - INFO - Epoch 001 Batch 1100/1563 - Loss: 1.6291
2025-09-10 17:58:12,587 - INFO - Epoch 001 Batch 1200/1563 - Loss: 1.6671
2025-09-10 17:58:14,211 - INFO - Epoch 001 Batch 1300/1563 - Loss: 1.3838
2025-09-10 17:58:15,843 - INFO - Epoch 001 Batch 1400/1563 - Loss: 1.3356
2025-09-10 17:58:17,442 - INFO - Epoch 001 Batch 1500/1563 - Loss: 1.6527
2025-09-10 17:58:18,455 - INFO - Epoch 001: Train Loss = 1.7348
2025-09-10 17:58:20,070 - INFO - Epoch 002 Batch 0100/1563 - Loss: 1.6317
2025-09-10 17:58:21,686 - INFO - Epoch 002 Batch 0200/1563 - Loss: 1.5570
2025-09-10 17:58:23,304 - INFO - Epoch 002 Batch 0300/1563 - Loss: 1.4169
2025-09-10 17:58:24,918 - INFO - Epoch 002 Batch 0400/1563 - Loss: 1.4808
2025-09-10 17:58:26,540 - INFO - Epoch 002 Batch 0500/1563 - Loss: 1.0749
2025-09-10 17:58:28,136 - INFO - Epoch 002 Batch 0600/1563 - Loss: 1.3111
2025-09-10 17:58:29,756 - INFO - Epoch 002 Batch 0700/1563 - Loss: 1.2149
2025-09-10 17:58:31,378 - INFO - Epoch 002 Batch 0800/1563 - Loss: 1.4727
2025-09-10 17:58:32,985 - INFO - Epoch 002 Batch 0900/1563 - Loss: 1.0043
2025-09-10 17:58:34,597 - INFO - Epoch 002 Batch 1000/1563 - Loss: 1.2753
2025-09-10 17:58:36,220 - INFO - Epoch 002 Batch 1100/1563 - Loss: 1.3018
2025-09-10 17:58:37,841 - INFO - Epoch 002 Batch 1200/1563 - Loss: 1.3719
2025-09-10 17:58:39,473 - INFO - Epoch 002 Batch 1300/1563 - Loss: 1.3668
2025-09-10 17:58:41,092 - INFO - Epoch 002 Batch 1400/1563 - Loss: 1.2877
2025-09-10 17:58:42,729 - INFO - Epoch 002 Batch 1500/1563 - Loss: 1.6055
2025-09-10 17:58:43,751 - INFO - Epoch 002: Train Loss = 1.3568
2025-09-10 17:58:45,370 - INFO - Epoch 003 Batch 0100/1563 - Loss: 1.2526
2025-09-10 17:58:46,990 - INFO - Epoch 003 Batch 0200/1563 - Loss: 1.0097
2025-09-10 17:58:48,626 - INFO - Epoch 003 Batch 0300/1563 - Loss: 1.2578
2025-09-10 17:58:50,269 - INFO - Epoch 003 Batch 0400/1563 - Loss: 1.2348
2025-09-10 17:58:51,900 - INFO - Epoch 003 Batch 0500/1563 - Loss: 1.4822
2025-09-10 17:58:53,516 - INFO - Epoch 003 Batch 0600/1563 - Loss: 1.2071
2025-09-10 17:58:55,149 - INFO - Epoch 003 Batch 0700/1563 - Loss: 1.0628
2025-09-10 17:58:56,797 - INFO - Epoch 003 Batch 0800/1563 - Loss: 1.3831
2025-09-10 17:58:58,440 - INFO - Epoch 003 Batch 0900/1563 - Loss: 1.1818
2025-09-10 17:59:00,066 - INFO - Epoch 003 Batch 1000/1563 - Loss: 1.2547
2025-09-10 17:59:01,729 - INFO - Epoch 003 Batch 1100/1563 - Loss: 1.3809
2025-09-10 17:59:03,356 - INFO - Epoch 003 Batch 1200/1563 - Loss: 1.0947
2025-09-10 17:59:04,976 - INFO - Epoch 003 Batch 1300/1563 - Loss: 1.0582
2025-09-10 17:59:06,654 - INFO - Epoch 003 Batch 1400/1563 - Loss: 1.3481
2025-09-10 17:59:08,289 - INFO - Epoch 003 Batch 1500/1563 - Loss: 1.1479
2025-09-10 17:59:09,315 - INFO - Epoch 003: Train Loss = 1.1873
2025-09-10 17:59:10,946 - INFO - Epoch 004 Batch 0100/1563 - Loss: 1.1210
2025-09-10 17:59:12,563 - INFO - Epoch 004 Batch 0200/1563 - Loss: 1.0070
2025-09-10 17:59:14,211 - INFO - Epoch 004 Batch 0300/1563 - Loss: 1.1935
2025-09-10 17:59:15,836 - INFO - Epoch 004 Batch 0400/1563 - Loss: 0.9162
2025-09-10 17:59:17,461 - INFO - Epoch 004 Batch 0500/1563 - Loss: 0.7355
2025-09-10 17:59:19,103 - INFO - Epoch 004 Batch 0600/1563 - Loss: 1.2776
2025-09-10 17:59:20,780 - INFO - Epoch 004 Batch 0700/1563 - Loss: 1.0676
2025-09-10 17:59:22,470 - INFO - Epoch 004 Batch 0800/1563 - Loss: 0.7744
2025-09-10 17:59:24,121 - INFO - Epoch 004 Batch 0900/1563 - Loss: 0.7436
2025-09-10 17:59:25,770 - INFO - Epoch 004 Batch 1000/1563 - Loss: 1.0761
2025-09-10 17:59:27,411 - INFO - Epoch 004 Batch 1100/1563 - Loss: 0.7097
2025-09-10 17:59:29,070 - INFO - Epoch 004 Batch 1200/1563 - Loss: 0.8613
2025-09-10 17:59:30,730 - INFO - Epoch 004 Batch 1300/1563 - Loss: 1.1868
2025-09-10 17:59:32,356 - INFO - Epoch 004 Batch 1400/1563 - Loss: 0.8305
2025-09-10 17:59:34,022 - INFO - Epoch 004 Batch 1500/1563 - Loss: 0.9340
2025-09-10 17:59:35,044 - INFO - Epoch 004: Train Loss = 1.0555
2025-09-10 17:59:36,704 - INFO - Epoch 005 Batch 0100/1563 - Loss: 1.1724
2025-09-10 17:59:38,313 - INFO - Epoch 005 Batch 0200/1563 - Loss: 0.9366
2025-09-10 17:59:39,959 - INFO - Epoch 005 Batch 0300/1563 - Loss: 1.0436
2025-09-10 17:59:41,600 - INFO - Epoch 005 Batch 0400/1563 - Loss: 1.2982
2025-09-10 17:59:43,241 - INFO - Epoch 005 Batch 0500/1563 - Loss: 1.0737
2025-09-10 17:59:44,894 - INFO - Epoch 005 Batch 0600/1563 - Loss: 1.0792
2025-09-10 17:59:46,554 - INFO - Epoch 005 Batch 0700/1563 - Loss: 0.9887
2025-09-10 17:59:48,207 - INFO - Epoch 005 Batch 0800/1563 - Loss: 1.0611
2025-09-10 17:59:49,865 - INFO - Epoch 005 Batch 0900/1563 - Loss: 1.1072
2025-09-10 17:59:51,501 - INFO - Epoch 005 Batch 1000/1563 - Loss: 1.1274
2025-09-10 17:59:53,135 - INFO - Epoch 005 Batch 1100/1563 - Loss: 1.0018
2025-09-10 17:59:54,746 - INFO - Epoch 005 Batch 1200/1563 - Loss: 0.7432
2025-09-10 17:59:56,399 - INFO - Epoch 005 Batch 1300/1563 - Loss: 0.9144
2025-09-10 17:59:58,021 - INFO - Epoch 005 Batch 1400/1563 - Loss: 1.1433
2025-09-10 17:59:59,653 - INFO - Epoch 005 Batch 1500/1563 - Loss: 0.9237
2025-09-10 18:00:00,674 - INFO - Epoch 005: Train Loss = 0.9487
2025-09-10 18:00:02,332 - INFO - Epoch 006 Batch 0100/1563 - Loss: 0.6364
2025-09-10 18:00:04,047 - INFO - Epoch 006 Batch 0200/1563 - Loss: 0.9662
2025-09-10 18:00:05,741 - INFO - Epoch 006 Batch 0300/1563 - Loss: 0.8792
2025-09-10 18:00:07,458 - INFO - Epoch 006 Batch 0400/1563 - Loss: 0.7249
2025-09-10 18:00:09,172 - INFO - Epoch 006 Batch 0500/1563 - Loss: 0.5944
2025-09-10 18:00:10,847 - INFO - Epoch 006 Batch 0600/1563 - Loss: 0.9574
2025-09-10 18:00:12,535 - INFO - Epoch 006 Batch 0700/1563 - Loss: 0.8177
2025-09-10 18:00:14,224 - INFO - Epoch 006 Batch 0800/1563 - Loss: 0.9438
2025-09-10 18:00:15,940 - INFO - Epoch 006 Batch 0900/1563 - Loss: 0.8493
2025-09-10 18:00:17,633 - INFO - Epoch 006 Batch 1000/1563 - Loss: 1.0048
2025-09-10 18:00:19,335 - INFO - Epoch 006 Batch 1100/1563 - Loss: 1.2103
2025-09-10 18:00:21,015 - INFO - Epoch 006 Batch 1200/1563 - Loss: 1.2836
2025-09-10 18:00:22,711 - INFO - Epoch 006 Batch 1300/1563 - Loss: 0.4402
2025-09-10 18:00:24,385 - INFO - Epoch 006 Batch 1400/1563 - Loss: 0.7035
2025-09-10 18:00:26,078 - INFO - Epoch 006 Batch 1500/1563 - Loss: 0.5897
2025-09-10 18:00:27,169 - INFO - Epoch 006: Train Loss = 0.8582
2025-09-10 18:00:28,876 - INFO - Epoch 007 Batch 0100/1563 - Loss: 0.7087
2025-09-10 18:00:30,634 - INFO - Epoch 007 Batch 0200/1563 - Loss: 0.8728
2025-09-10 18:00:32,371 - INFO - Epoch 007 Batch 0300/1563 - Loss: 1.0515
2025-09-10 18:00:34,091 - INFO - Epoch 007 Batch 0400/1563 - Loss: 1.0243
2025-09-10 18:00:35,842 - INFO - Epoch 007 Batch 0500/1563 - Loss: 0.9738
2025-09-10 18:00:37,615 - INFO - Epoch 007 Batch 0600/1563 - Loss: 0.5902
2025-09-10 18:00:39,351 - INFO - Epoch 007 Batch 0700/1563 - Loss: 1.0576
2025-09-10 18:00:41,068 - INFO - Epoch 007 Batch 0800/1563 - Loss: 0.9186
2025-09-10 18:00:42,829 - INFO - Epoch 007 Batch 0900/1563 - Loss: 0.4890
2025-09-10 18:00:44,585 - INFO - Epoch 007 Batch 1000/1563 - Loss: 0.6533
2025-09-10 18:00:46,328 - INFO - Epoch 007 Batch 1100/1563 - Loss: 0.8968
2025-09-10 18:00:48,027 - INFO - Epoch 007 Batch 1200/1563 - Loss: 0.8777
2025-09-10 18:00:49,746 - INFO - Epoch 007 Batch 1300/1563 - Loss: 0.7879
2025-09-10 18:00:51,451 - INFO - Epoch 007 Batch 1400/1563 - Loss: 0.6304
2025-09-10 18:00:53,185 - INFO - Epoch 007 Batch 1500/1563 - Loss: 0.6569
2025-09-10 18:00:54,255 - INFO - Epoch 007: Train Loss = 0.7792
2025-09-10 18:00:55,960 - INFO - Epoch 008 Batch 0100/1563 - Loss: 0.5114
2025-09-10 18:00:57,673 - INFO - Epoch 008 Batch 0200/1563 - Loss: 0.9340
2025-09-10 18:00:59,360 - INFO - Epoch 008 Batch 0300/1563 - Loss: 1.1674
2025-09-10 18:01:01,045 - INFO - Epoch 008 Batch 0400/1563 - Loss: 0.4739
2025-09-10 18:01:02,755 - INFO - Epoch 008 Batch 0500/1563 - Loss: 0.4703
2025-09-10 18:01:04,474 - INFO - Epoch 008 Batch 0600/1563 - Loss: 0.3598
2025-09-10 18:01:06,237 - INFO - Epoch 008 Batch 0700/1563 - Loss: 0.6860
2025-09-10 18:01:07,933 - INFO - Epoch 008 Batch 0800/1563 - Loss: 0.5847
2025-09-10 18:01:09,614 - INFO - Epoch 008 Batch 0900/1563 - Loss: 0.8882
2025-09-10 18:01:11,289 - INFO - Epoch 008 Batch 1000/1563 - Loss: 0.6010
2025-09-10 18:01:12,965 - INFO - Epoch 008 Batch 1100/1563 - Loss: 0.4205
2025-09-10 18:01:14,677 - INFO - Epoch 008 Batch 1200/1563 - Loss: 0.5830
2025-09-10 18:01:16,438 - INFO - Epoch 008 Batch 1300/1563 - Loss: 0.5801
2025-09-10 18:01:18,128 - INFO - Epoch 008 Batch 1400/1563 - Loss: 0.8914
2025-09-10 18:01:19,815 - INFO - Epoch 008 Batch 1500/1563 - Loss: 0.6081
2025-09-10 18:01:20,892 - INFO - Epoch 008: Train Loss = 0.7077
2025-09-10 18:01:22,596 - INFO - Epoch 009 Batch 0100/1563 - Loss: 0.3299
2025-09-10 18:01:24,348 - INFO - Epoch 009 Batch 0200/1563 - Loss: 0.9759
2025-09-10 18:01:26,143 - INFO - Epoch 009 Batch 0300/1563 - Loss: 0.4265
2025-09-10 18:01:27,844 - INFO - Epoch 009 Batch 0400/1563 - Loss: 0.5062
2025-09-10 18:01:29,550 - INFO - Epoch 009 Batch 0500/1563 - Loss: 0.4751
2025-09-10 18:01:31,251 - INFO - Epoch 009 Batch 0600/1563 - Loss: 0.7157
2025-09-10 18:01:32,933 - INFO - Epoch 009 Batch 0700/1563 - Loss: 0.4266
2025-09-10 18:01:34,618 - INFO - Epoch 009 Batch 0800/1563 - Loss: 0.7892
2025-09-10 18:01:36,285 - INFO - Epoch 009 Batch 0900/1563 - Loss: 0.7069
2025-09-10 18:01:37,991 - INFO - Epoch 009 Batch 1000/1563 - Loss: 0.4795
2025-09-10 18:01:39,643 - INFO - Epoch 009 Batch 1100/1563 - Loss: 0.8356
2025-09-10 18:01:41,302 - INFO - Epoch 009 Batch 1200/1563 - Loss: 0.9302
2025-09-10 18:01:42,956 - INFO - Epoch 009 Batch 1300/1563 - Loss: 0.7130
2025-09-10 18:01:44,675 - INFO - Epoch 009 Batch 1400/1563 - Loss: 0.3995
2025-09-10 18:01:46,328 - INFO - Epoch 009 Batch 1500/1563 - Loss: 0.5792
2025-09-10 18:01:47,383 - INFO - Epoch 009: Train Loss = 0.6418
2025-09-10 18:01:49,083 - INFO - Epoch 010 Batch 0100/1563 - Loss: 0.6074
2025-09-10 18:01:50,774 - INFO - Epoch 010 Batch 0200/1563 - Loss: 0.9985
2025-09-10 18:01:52,470 - INFO - Epoch 010 Batch 0300/1563 - Loss: 0.5578
2025-09-10 18:01:54,176 - INFO - Epoch 010 Batch 0400/1563 - Loss: 0.5829
2025-09-10 18:01:55,869 - INFO - Epoch 010 Batch 0500/1563 - Loss: 0.7287
2025-09-10 18:01:57,549 - INFO - Epoch 010 Batch 0600/1563 - Loss: 0.7323
2025-09-10 18:01:59,228 - INFO - Epoch 010 Batch 0700/1563 - Loss: 0.4969
2025-09-10 18:02:00,911 - INFO - Epoch 010 Batch 0800/1563 - Loss: 0.3200
2025-09-10 18:02:02,643 - INFO - Epoch 010 Batch 0900/1563 - Loss: 0.4859
2025-09-10 18:02:04,323 - INFO - Epoch 010 Batch 1000/1563 - Loss: 0.6440
2025-09-10 18:02:06,009 - INFO - Epoch 010 Batch 1100/1563 - Loss: 0.4788
2025-09-10 18:02:07,724 - INFO - Epoch 010 Batch 1200/1563 - Loss: 0.6519
2025-09-10 18:02:09,426 - INFO - Epoch 010 Batch 1300/1563 - Loss: 0.7494
2025-09-10 18:02:11,100 - INFO - Epoch 010 Batch 1400/1563 - Loss: 0.5900
2025-09-10 18:02:12,809 - INFO - Epoch 010 Batch 1500/1563 - Loss: 0.4647
2025-09-10 18:02:13,881 - INFO - Epoch 010: Train Loss = 0.5777
2025-09-10 18:06:00,645 - INFO - Epoch 001 Batch 0100/1563 - Loss: 2.1759
2025-09-10 18:06:02,363 - INFO - Epoch 001 Batch 0200/1563 - Loss: 2.0964
2025-09-10 18:06:04,074 - INFO - Epoch 001 Batch 0300/1563 - Loss: 2.0371
2025-09-10 18:06:05,745 - INFO - Epoch 001 Batch 0400/1563 - Loss: 1.7703
2025-09-10 18:06:07,451 - INFO - Epoch 001 Batch 0500/1563 - Loss: 1.7522
2025-09-10 18:06:09,135 - INFO - Epoch 001 Batch 0600/1563 - Loss: 1.7779
2025-09-10 18:06:10,764 - INFO - Epoch 001 Batch 0700/1563 - Loss: 1.6374
2025-09-10 18:06:12,436 - INFO - Epoch 001 Batch 0800/1563 - Loss: 1.7399
2025-09-10 18:06:14,159 - INFO - Epoch 001 Batch 0900/1563 - Loss: 1.5837
2025-09-10 18:06:15,868 - INFO - Epoch 001 Batch 1000/1563 - Loss: 1.8309
2025-09-10 18:06:17,582 - INFO - Epoch 001 Batch 1100/1563 - Loss: 1.3712
2025-09-10 18:06:19,267 - INFO - Epoch 001 Batch 1200/1563 - Loss: 1.5506
2025-09-10 18:06:20,979 - INFO - Epoch 001 Batch 1300/1563 - Loss: 1.3436
2025-09-10 18:06:22,645 - INFO - Epoch 001 Batch 1400/1563 - Loss: 1.4473
2025-09-10 18:06:24,379 - INFO - Epoch 001 Batch 1500/1563 - Loss: 1.5191
2025-09-10 18:06:25,447 - INFO - Epoch 001: Train Loss = 1.7070
2025-09-10 18:06:27,126 - INFO - Epoch 002 Batch 0100/1563 - Loss: 1.2551
2025-09-10 18:06:28,826 - INFO - Epoch 002 Batch 0200/1563 - Loss: 1.4964
2025-09-10 18:06:30,535 - INFO - Epoch 002 Batch 0300/1563 - Loss: 1.1190
2025-09-10 18:06:32,242 - INFO - Epoch 002 Batch 0400/1563 - Loss: 1.2895
2025-09-10 18:06:33,987 - INFO - Epoch 002 Batch 0500/1563 - Loss: 1.4336
2025-09-10 18:06:35,658 - INFO - Epoch 002 Batch 0600/1563 - Loss: 1.1785
2025-09-10 18:06:37,366 - INFO - Epoch 002 Batch 0700/1563 - Loss: 1.3981
2025-09-10 18:06:39,020 - INFO - Epoch 002 Batch 0800/1563 - Loss: 1.0049
2025-09-10 18:06:40,649 - INFO - Epoch 002 Batch 0900/1563 - Loss: 1.4478
2025-09-10 18:06:42,324 - INFO - Epoch 002 Batch 1000/1563 - Loss: 1.0291
2025-09-10 18:06:44,019 - INFO - Epoch 002 Batch 1100/1563 - Loss: 1.5599
2025-09-10 18:06:45,713 - INFO - Epoch 002 Batch 1200/1563 - Loss: 0.9242
2025-09-10 18:06:47,421 - INFO - Epoch 002 Batch 1300/1563 - Loss: 1.1262
2025-09-10 18:06:49,164 - INFO - Epoch 002 Batch 1400/1563 - Loss: 1.1726
2025-09-10 18:06:50,854 - INFO - Epoch 002 Batch 1500/1563 - Loss: 1.1788
2025-09-10 18:06:51,898 - INFO - Epoch 002: Train Loss = 1.3294
2025-09-10 18:06:53,599 - INFO - Epoch 003 Batch 0100/1563 - Loss: 1.1426
2025-09-10 18:06:55,309 - INFO - Epoch 003 Batch 0200/1563 - Loss: 1.1076
2025-09-10 18:06:57,021 - INFO - Epoch 003 Batch 0300/1563 - Loss: 1.1636
2025-09-10 18:06:58,710 - INFO - Epoch 003 Batch 0400/1563 - Loss: 1.1016
2025-09-10 18:07:00,386 - INFO - Epoch 003 Batch 0500/1563 - Loss: 1.0512
2025-09-10 18:07:02,120 - INFO - Epoch 003 Batch 0600/1563 - Loss: 1.2479
2025-09-10 18:07:03,830 - INFO - Epoch 003 Batch 0700/1563 - Loss: 1.3417
2025-09-10 18:07:05,574 - INFO - Epoch 003 Batch 0800/1563 - Loss: 1.2527
2025-09-10 18:07:07,264 - INFO - Epoch 003 Batch 0900/1563 - Loss: 1.0099
2025-09-10 18:07:08,964 - INFO - Epoch 003 Batch 1000/1563 - Loss: 0.9331
2025-09-10 18:07:10,639 - INFO - Epoch 003 Batch 1100/1563 - Loss: 1.4589
2025-09-10 18:07:12,321 - INFO - Epoch 003 Batch 1200/1563 - Loss: 1.0711
2025-09-10 18:07:14,024 - INFO - Epoch 003 Batch 1300/1563 - Loss: 1.3454
2025-09-10 18:07:15,695 - INFO - Epoch 003 Batch 1400/1563 - Loss: 1.3251
2025-09-10 18:07:17,385 - INFO - Epoch 003 Batch 1500/1563 - Loss: 1.1949
2025-09-10 18:07:18,444 - INFO - Epoch 003: Train Loss = 1.1549
2025-09-10 18:07:20,161 - INFO - Epoch 004 Batch 0100/1563 - Loss: 1.2598
2025-09-10 18:07:21,858 - INFO - Epoch 004 Batch 0200/1563 - Loss: 0.9339
2025-09-10 18:07:23,584 - INFO - Epoch 004 Batch 0300/1563 - Loss: 0.8881
2025-09-10 18:07:25,276 - INFO - Epoch 004 Batch 0400/1563 - Loss: 0.7384
2025-09-10 18:07:26,955 - INFO - Epoch 004 Batch 0500/1563 - Loss: 1.0714
2025-09-10 18:07:28,647 - INFO - Epoch 004 Batch 0600/1563 - Loss: 1.0948
2025-09-10 18:07:30,304 - INFO - Epoch 004 Batch 0700/1563 - Loss: 1.0412
2025-09-10 18:07:31,964 - INFO - Epoch 004 Batch 0800/1563 - Loss: 1.1761
2025-09-10 18:07:33,646 - INFO - Epoch 004 Batch 0900/1563 - Loss: 0.8250
2025-09-10 18:07:35,350 - INFO - Epoch 004 Batch 1000/1563 - Loss: 1.1410
2025-09-10 18:07:37,042 - INFO - Epoch 004 Batch 1100/1563 - Loss: 1.0710
2025-09-10 18:07:38,722 - INFO - Epoch 004 Batch 1200/1563 - Loss: 0.8929
2025-09-10 18:07:40,378 - INFO - Epoch 004 Batch 1300/1563 - Loss: 0.8264
2025-09-10 18:07:42,072 - INFO - Epoch 004 Batch 1400/1563 - Loss: 1.2762
2025-09-10 18:07:43,774 - INFO - Epoch 004 Batch 1500/1563 - Loss: 0.8716
2025-09-10 18:07:44,818 - INFO - Epoch 004: Train Loss = 1.0296
2025-09-10 18:07:46,502 - INFO - Epoch 005 Batch 0100/1563 - Loss: 0.6821
2025-09-10 18:07:48,216 - INFO - Epoch 005 Batch 0200/1563 - Loss: 1.3723
2025-09-10 18:07:49,911 - INFO - Epoch 005 Batch 0300/1563 - Loss: 1.1049
2025-09-10 18:07:51,575 - INFO - Epoch 005 Batch 0400/1563 - Loss: 0.7898
2025-09-10 18:07:53,251 - INFO - Epoch 005 Batch 0500/1563 - Loss: 0.9226
2025-09-10 18:07:54,896 - INFO - Epoch 005 Batch 0600/1563 - Loss: 0.4492
2025-09-10 18:07:56,576 - INFO - Epoch 005 Batch 0700/1563 - Loss: 1.1402
2025-09-10 18:07:58,218 - INFO - Epoch 005 Batch 0800/1563 - Loss: 1.0305
2025-09-10 18:07:59,861 - INFO - Epoch 005 Batch 0900/1563 - Loss: 1.3187
2025-09-10 18:08:01,556 - INFO - Epoch 005 Batch 1000/1563 - Loss: 1.4549
2025-09-10 18:08:03,225 - INFO - Epoch 005 Batch 1100/1563 - Loss: 0.8523
2025-09-10 18:08:04,911 - INFO - Epoch 005 Batch 1200/1563 - Loss: 1.0579
2025-09-10 18:08:06,561 - INFO - Epoch 005 Batch 1300/1563 - Loss: 1.5868
2025-09-10 18:08:08,222 - INFO - Epoch 005 Batch 1400/1563 - Loss: 0.6616
2025-09-10 18:08:09,869 - INFO - Epoch 005 Batch 1500/1563 - Loss: 0.5307
2025-09-10 18:08:10,907 - INFO - Epoch 005: Train Loss = 0.9323
2025-09-10 18:08:12,584 - INFO - Epoch 006 Batch 0100/1563 - Loss: 1.0618
2025-09-10 18:08:14,274 - INFO - Epoch 006 Batch 0200/1563 - Loss: 1.0562
2025-09-10 18:08:15,966 - INFO - Epoch 006 Batch 0300/1563 - Loss: 0.5105
2025-09-10 18:08:17,589 - INFO - Epoch 006 Batch 0400/1563 - Loss: 1.0135
2025-09-10 18:08:19,235 - INFO - Epoch 006 Batch 0500/1563 - Loss: 0.8021
2025-09-10 18:08:20,884 - INFO - Epoch 006 Batch 0600/1563 - Loss: 0.9989
2025-09-10 18:08:22,514 - INFO - Epoch 006 Batch 0700/1563 - Loss: 1.0172
2025-09-10 18:08:24,149 - INFO - Epoch 006 Batch 0800/1563 - Loss: 0.7816
2025-09-10 18:08:25,819 - INFO - Epoch 006 Batch 0900/1563 - Loss: 0.6689
2025-09-10 18:08:27,442 - INFO - Epoch 006 Batch 1000/1563 - Loss: 1.0452
2025-09-10 18:08:29,072 - INFO - Epoch 006 Batch 1100/1563 - Loss: 0.6512
2025-09-10 18:08:30,747 - INFO - Epoch 006 Batch 1200/1563 - Loss: 0.5529
2025-09-10 18:08:32,436 - INFO - Epoch 006 Batch 1300/1563 - Loss: 0.9774
2025-09-10 18:08:34,135 - INFO - Epoch 006 Batch 1400/1563 - Loss: 0.6303
2025-09-10 18:08:35,804 - INFO - Epoch 006 Batch 1500/1563 - Loss: 0.6109
2025-09-10 18:08:36,856 - INFO - Epoch 006: Train Loss = 0.8472
2025-09-10 18:08:38,512 - INFO - Epoch 007 Batch 0100/1563 - Loss: 0.7922
2025-09-10 18:08:40,174 - INFO - Epoch 007 Batch 0200/1563 - Loss: 0.7953
2025-09-10 18:08:41,834 - INFO - Epoch 007 Batch 0300/1563 - Loss: 0.6750
2025-09-10 18:08:43,469 - INFO - Epoch 007 Batch 0400/1563 - Loss: 0.7808
2025-09-10 18:08:45,112 - INFO - Epoch 007 Batch 0500/1563 - Loss: 0.9642
2025-09-10 18:08:46,785 - INFO - Epoch 007 Batch 0600/1563 - Loss: 0.9765
2025-09-10 18:08:48,446 - INFO - Epoch 007 Batch 0700/1563 - Loss: 0.6397
2025-09-10 18:08:50,123 - INFO - Epoch 007 Batch 0800/1563 - Loss: 0.7131
2025-09-10 18:08:51,768 - INFO - Epoch 007 Batch 0900/1563 - Loss: 0.8184
2025-09-10 18:08:53,417 - INFO - Epoch 007 Batch 1000/1563 - Loss: 0.8902
2025-09-10 18:08:55,043 - INFO - Epoch 007 Batch 1100/1563 - Loss: 0.8324
2025-09-10 18:08:56,710 - INFO - Epoch 007 Batch 1200/1563 - Loss: 0.8315
2025-09-10 18:08:58,332 - INFO - Epoch 007 Batch 1300/1563 - Loss: 0.3850
2025-09-10 18:09:00,039 - INFO - Epoch 007 Batch 1400/1563 - Loss: 0.7086
2025-09-10 18:09:01,702 - INFO - Epoch 007 Batch 1500/1563 - Loss: 0.7715
2025-09-10 18:09:02,752 - INFO - Epoch 007: Train Loss = 0.7693
2025-09-10 18:09:04,384 - INFO - Epoch 008 Batch 0100/1563 - Loss: 0.6676
2025-09-10 18:09:06,041 - INFO - Epoch 008 Batch 0200/1563 - Loss: 0.7523
2025-09-10 18:09:07,690 - INFO - Epoch 008 Batch 0300/1563 - Loss: 0.8263
2025-09-10 18:09:09,344 - INFO - Epoch 008 Batch 0400/1563 - Loss: 1.0081
2025-09-10 18:09:11,005 - INFO - Epoch 008 Batch 0500/1563 - Loss: 0.5047
2025-09-10 18:09:12,649 - INFO - Epoch 008 Batch 0600/1563 - Loss: 0.7038
2025-09-10 18:09:14,333 - INFO - Epoch 008 Batch 0700/1563 - Loss: 0.5768
2025-09-10 18:09:15,995 - INFO - Epoch 008 Batch 0800/1563 - Loss: 0.7121
2025-09-10 18:09:17,708 - INFO - Epoch 008 Batch 0900/1563 - Loss: 0.6622
2025-09-10 18:09:19,412 - INFO - Epoch 008 Batch 1000/1563 - Loss: 0.7374
2025-09-10 18:09:21,132 - INFO - Epoch 008 Batch 1100/1563 - Loss: 0.7342
2025-09-10 18:09:22,781 - INFO - Epoch 008 Batch 1200/1563 - Loss: 0.7454
2025-09-10 18:09:24,438 - INFO - Epoch 008 Batch 1300/1563 - Loss: 0.7163
2025-09-10 18:09:26,105 - INFO - Epoch 008 Batch 1400/1563 - Loss: 0.9401
2025-09-10 18:09:27,759 - INFO - Epoch 008 Batch 1500/1563 - Loss: 0.8444
2025-09-10 18:09:28,823 - INFO - Epoch 008: Train Loss = 0.6978
2025-09-10 18:09:30,480 - INFO - Epoch 009 Batch 0100/1563 - Loss: 0.3586
2025-09-10 18:09:32,166 - INFO - Epoch 009 Batch 0200/1563 - Loss: 0.7549
2025-09-10 18:09:33,880 - INFO - Epoch 009 Batch 0300/1563 - Loss: 0.5308
2025-09-10 18:09:35,584 - INFO - Epoch 009 Batch 0400/1563 - Loss: 0.4694
2025-09-10 18:09:37,296 - INFO - Epoch 009 Batch 0500/1563 - Loss: 0.3699
2025-09-10 18:09:38,950 - INFO - Epoch 009 Batch 0600/1563 - Loss: 0.6560
2025-09-10 18:09:40,634 - INFO - Epoch 009 Batch 0700/1563 - Loss: 0.6393
2025-09-10 18:09:42,266 - INFO - Epoch 009 Batch 0800/1563 - Loss: 0.4251
2025-09-10 18:09:43,944 - INFO - Epoch 009 Batch 0900/1563 - Loss: 0.3686
2025-09-10 18:09:45,603 - INFO - Epoch 009 Batch 1000/1563 - Loss: 0.7412
2025-09-10 18:09:47,277 - INFO - Epoch 009 Batch 1100/1563 - Loss: 0.4359
2025-09-10 18:09:48,977 - INFO - Epoch 009 Batch 1200/1563 - Loss: 0.6203
2025-09-10 18:09:50,659 - INFO - Epoch 009 Batch 1300/1563 - Loss: 0.7386
2025-09-10 18:09:52,346 - INFO - Epoch 009 Batch 1400/1563 - Loss: 0.6941
2025-09-10 18:09:54,047 - INFO - Epoch 009 Batch 1500/1563 - Loss: 0.6006
2025-09-10 18:09:55,108 - INFO - Epoch 009: Train Loss = 0.6302
2025-09-10 18:09:56,827 - INFO - Epoch 010 Batch 0100/1563 - Loss: 0.5780
2025-09-10 18:09:58,481 - INFO - Epoch 010 Batch 0200/1563 - Loss: 0.7268
2025-09-10 18:10:00,158 - INFO - Epoch 010 Batch 0300/1563 - Loss: 0.6319
2025-09-10 18:10:01,843 - INFO - Epoch 010 Batch 0400/1563 - Loss: 0.7815
2025-09-10 18:10:03,553 - INFO - Epoch 010 Batch 0500/1563 - Loss: 0.5329
2025-09-10 18:10:05,220 - INFO - Epoch 010 Batch 0600/1563 - Loss: 0.8518
2025-09-10 18:10:06,890 - INFO - Epoch 010 Batch 0700/1563 - Loss: 0.4442
2025-09-10 18:10:08,572 - INFO - Epoch 010 Batch 0800/1563 - Loss: 0.2297
2025-09-10 18:10:10,234 - INFO - Epoch 010 Batch 0900/1563 - Loss: 0.6355
2025-09-10 18:10:11,949 - INFO - Epoch 010 Batch 1000/1563 - Loss: 0.7378
2025-09-10 18:10:13,642 - INFO - Epoch 010 Batch 1100/1563 - Loss: 0.5497
2025-09-10 18:10:15,358 - INFO - Epoch 010 Batch 1200/1563 - Loss: 0.6137
2025-09-10 18:10:17,039 - INFO - Epoch 010 Batch 1300/1563 - Loss: 0.6409
2025-09-10 18:10:18,724 - INFO - Epoch 010 Batch 1400/1563 - Loss: 0.2957
2025-09-10 18:10:20,384 - INFO - Epoch 010 Batch 1500/1563 - Loss: 0.6379
2025-09-10 18:10:21,439 - INFO - Epoch 010: Train Loss = 0.5669
2025-09-10 18:10:24,505 - INFO - Test Loss: 0.8617 | Test Accuracy: 70.99%
2025-09-10 18:10:26,209 - INFO - Epoch 011 Batch 0100/1563 - Loss: 0.4173
2025-09-10 18:10:27,883 - INFO - Epoch 011 Batch 0200/1563 - Loss: 0.3946
2025-09-10 18:10:29,595 - INFO - Epoch 011 Batch 0300/1563 - Loss: 0.8375
2025-09-10 18:10:31,315 - INFO - Epoch 011 Batch 0400/1563 - Loss: 0.3413
2025-09-10 18:10:32,988 - INFO - Epoch 011 Batch 0500/1563 - Loss: 0.5784
2025-09-10 18:10:34,628 - INFO - Epoch 011 Batch 0600/1563 - Loss: 0.6702
2025-09-10 18:10:36,306 - INFO - Epoch 011 Batch 0700/1563 - Loss: 0.2917
2025-09-10 18:10:38,033 - INFO - Epoch 011 Batch 0800/1563 - Loss: 0.8894
2025-09-10 18:10:39,768 - INFO - Epoch 011 Batch 0900/1563 - Loss: 0.3000
2025-09-10 18:10:41,485 - INFO - Epoch 011 Batch 1000/1563 - Loss: 0.4144
2025-09-10 18:10:43,158 - INFO - Epoch 011 Batch 1100/1563 - Loss: 0.4403
2025-09-10 18:10:44,880 - INFO - Epoch 011 Batch 1200/1563 - Loss: 0.5000
2025-09-10 18:10:46,604 - INFO - Epoch 011 Batch 1300/1563 - Loss: 0.3403
2025-09-10 18:10:48,330 - INFO - Epoch 011 Batch 1400/1563 - Loss: 0.4868
2025-09-10 18:10:50,102 - INFO - Epoch 011 Batch 1500/1563 - Loss: 0.6947
2025-09-10 18:10:51,178 - INFO - Epoch 011: Train Loss = 0.5018
2025-09-10 18:10:52,909 - INFO - Epoch 012 Batch 0100/1563 - Loss: 0.4701
2025-09-10 18:10:54,646 - INFO - Epoch 012 Batch 0200/1563 - Loss: 0.3850
2025-09-10 18:10:56,345 - INFO - Epoch 012 Batch 0300/1563 - Loss: 0.5506
2025-09-10 18:10:58,050 - INFO - Epoch 012 Batch 0400/1563 - Loss: 0.3417
2025-09-10 18:10:59,805 - INFO - Epoch 012 Batch 0500/1563 - Loss: 0.4603
2025-09-10 18:11:01,545 - INFO - Epoch 012 Batch 0600/1563 - Loss: 0.2372
2025-09-10 18:11:03,279 - INFO - Epoch 012 Batch 0700/1563 - Loss: 0.2118
2025-09-10 18:11:05,049 - INFO - Epoch 012 Batch 0800/1563 - Loss: 0.4982
2025-09-10 18:11:06,774 - INFO - Epoch 012 Batch 0900/1563 - Loss: 0.5570
2025-09-10 18:11:08,465 - INFO - Epoch 012 Batch 1000/1563 - Loss: 0.3234
2025-09-10 18:11:10,122 - INFO - Epoch 012 Batch 1100/1563 - Loss: 0.2825
2025-09-10 18:11:11,801 - INFO - Epoch 012 Batch 1200/1563 - Loss: 0.3456
2025-09-10 18:11:13,496 - INFO - Epoch 012 Batch 1300/1563 - Loss: 0.4622
2025-09-10 18:11:15,175 - INFO - Epoch 012 Batch 1400/1563 - Loss: 0.4430
2025-09-10 18:11:16,832 - INFO - Epoch 012 Batch 1500/1563 - Loss: 0.3808
2025-09-10 18:11:17,852 - INFO - Epoch 012: Train Loss = 0.4403
2025-09-10 18:11:19,495 - INFO - Epoch 013 Batch 0100/1563 - Loss: 0.2196
2025-09-10 18:11:21,152 - INFO - Epoch 013 Batch 0200/1563 - Loss: 0.4882
2025-09-10 18:11:22,792 - INFO - Epoch 013 Batch 0300/1563 - Loss: 0.4340
2025-09-10 18:11:24,463 - INFO - Epoch 013 Batch 0400/1563 - Loss: 0.3275
2025-09-10 18:11:26,120 - INFO - Epoch 013 Batch 0500/1563 - Loss: 0.3753
2025-09-10 18:11:27,770 - INFO - Epoch 013 Batch 0600/1563 - Loss: 0.3578
2025-09-10 18:11:29,377 - INFO - Epoch 013 Batch 0700/1563 - Loss: 0.6221
2025-09-10 18:11:31,010 - INFO - Epoch 013 Batch 0800/1563 - Loss: 0.2528
2025-09-10 18:11:32,683 - INFO - Epoch 013 Batch 0900/1563 - Loss: 0.3374
2025-09-10 18:11:34,334 - INFO - Epoch 013 Batch 1000/1563 - Loss: 0.2490
2025-09-10 18:11:36,017 - INFO - Epoch 013 Batch 1100/1563 - Loss: 0.3120
2025-09-10 18:11:37,690 - INFO - Epoch 013 Batch 1200/1563 - Loss: 0.4428
2025-09-10 18:11:39,334 - INFO - Epoch 013 Batch 1300/1563 - Loss: 0.3529
2025-09-10 18:11:40,974 - INFO - Epoch 013 Batch 1400/1563 - Loss: 0.2937
2025-09-10 18:11:42,661 - INFO - Epoch 013 Batch 1500/1563 - Loss: 0.5678
2025-09-10 18:11:43,686 - INFO - Epoch 013: Train Loss = 0.3813
2025-09-10 18:11:45,359 - INFO - Epoch 014 Batch 0100/1563 - Loss: 0.2869
2025-09-10 18:11:46,980 - INFO - Epoch 014 Batch 0200/1563 - Loss: 0.1793
2025-09-10 18:11:48,651 - INFO - Epoch 014 Batch 0300/1563 - Loss: 0.2698
2025-09-10 18:11:50,324 - INFO - Epoch 014 Batch 0400/1563 - Loss: 0.4964
2025-09-10 18:11:52,009 - INFO - Epoch 014 Batch 0500/1563 - Loss: 0.3743
2025-09-10 18:11:53,706 - INFO - Epoch 014 Batch 0600/1563 - Loss: 0.4909
2025-09-10 18:11:55,362 - INFO - Epoch 014 Batch 0700/1563 - Loss: 0.3039
2025-09-10 18:11:57,004 - INFO - Epoch 014 Batch 0800/1563 - Loss: 0.2226
2025-09-10 18:11:58,657 - INFO - Epoch 014 Batch 0900/1563 - Loss: 0.4721
2025-09-10 18:12:00,291 - INFO - Epoch 014 Batch 1000/1563 - Loss: 0.1525
2025-09-10 18:12:01,966 - INFO - Epoch 014 Batch 1100/1563 - Loss: 0.4889
2025-09-10 18:12:03,653 - INFO - Epoch 014 Batch 1200/1563 - Loss: 0.2686
2025-09-10 18:12:05,288 - INFO - Epoch 014 Batch 1300/1563 - Loss: 0.3387
2025-09-10 18:12:06,942 - INFO - Epoch 014 Batch 1400/1563 - Loss: 0.3085
2025-09-10 18:12:08,623 - INFO - Epoch 014 Batch 1500/1563 - Loss: 0.3038
2025-09-10 18:12:09,666 - INFO - Epoch 014: Train Loss = 0.3222
2025-09-10 18:12:11,331 - INFO - Epoch 015 Batch 0100/1563 - Loss: 0.3066
2025-09-10 18:12:13,013 - INFO - Epoch 015 Batch 0200/1563 - Loss: 0.4620
2025-09-10 18:12:14,660 - INFO - Epoch 015 Batch 0300/1563 - Loss: 0.2910
2025-09-10 18:12:16,278 - INFO - Epoch 015 Batch 0400/1563 - Loss: 0.3043
2025-09-10 18:12:17,927 - INFO - Epoch 015 Batch 0500/1563 - Loss: 0.1678
2025-09-10 18:12:19,592 - INFO - Epoch 015 Batch 0600/1563 - Loss: 0.2628
2025-09-10 18:12:21,226 - INFO - Epoch 015 Batch 0700/1563 - Loss: 0.3532
2025-09-10 18:12:22,871 - INFO - Epoch 015 Batch 0800/1563 - Loss: 0.3722
2025-09-10 18:12:24,508 - INFO - Epoch 015 Batch 0900/1563 - Loss: 0.1559
2025-09-10 18:12:26,149 - INFO - Epoch 015 Batch 1000/1563 - Loss: 0.2525
2025-09-10 18:12:27,845 - INFO - Epoch 015 Batch 1100/1563 - Loss: 0.0973
2025-09-10 18:12:29,507 - INFO - Epoch 015 Batch 1200/1563 - Loss: 0.2968
2025-09-10 18:12:31,176 - INFO - Epoch 015 Batch 1300/1563 - Loss: 0.2769
2025-09-10 18:12:32,826 - INFO - Epoch 015 Batch 1400/1563 - Loss: 0.2811
2025-09-10 18:12:34,476 - INFO - Epoch 015 Batch 1500/1563 - Loss: 0.5093
2025-09-10 18:12:35,507 - INFO - Epoch 015: Train Loss = 0.2625
2025-09-10 18:12:37,152 - INFO - Epoch 016 Batch 0100/1563 - Loss: 0.1090
2025-09-10 18:12:38,794 - INFO - Epoch 016 Batch 0200/1563 - Loss: 0.2053
2025-09-10 18:12:40,440 - INFO - Epoch 016 Batch 0300/1563 - Loss: 0.2522
2025-09-10 18:12:42,105 - INFO - Epoch 016 Batch 0400/1563 - Loss: 0.2423
2025-09-10 18:12:43,769 - INFO - Epoch 016 Batch 0500/1563 - Loss: 0.2712
2025-09-10 18:12:45,450 - INFO - Epoch 016 Batch 0600/1563 - Loss: 0.2130
2025-09-10 18:12:47,063 - INFO - Epoch 016 Batch 0700/1563 - Loss: 0.2528
2025-09-10 18:12:48,721 - INFO - Epoch 016 Batch 0800/1563 - Loss: 0.4682
2025-09-10 18:12:50,424 - INFO - Epoch 016 Batch 0900/1563 - Loss: 0.2021
2025-09-10 18:12:52,071 - INFO - Epoch 016 Batch 1000/1563 - Loss: 0.2950
2025-09-10 18:12:53,768 - INFO - Epoch 016 Batch 1100/1563 - Loss: 0.1359
2025-09-10 18:12:55,410 - INFO - Epoch 016 Batch 1200/1563 - Loss: 0.1948
2025-09-10 18:12:57,059 - INFO - Epoch 016 Batch 1300/1563 - Loss: 0.2189
2025-09-10 18:12:58,664 - INFO - Epoch 016 Batch 1400/1563 - Loss: 0.2959
2025-09-10 18:13:00,308 - INFO - Epoch 016 Batch 1500/1563 - Loss: 0.1561
2025-09-10 18:13:01,323 - INFO - Epoch 016: Train Loss = 0.2139
2025-09-10 18:13:02,963 - INFO - Epoch 017 Batch 0100/1563 - Loss: 0.1257
2025-09-10 18:13:04,582 - INFO - Epoch 017 Batch 0200/1563 - Loss: 0.2281
2025-09-10 18:13:06,200 - INFO - Epoch 017 Batch 0300/1563 - Loss: 0.1839
2025-09-10 18:13:07,808 - INFO - Epoch 017 Batch 0400/1563 - Loss: 0.1961
2025-09-10 18:13:09,405 - INFO - Epoch 017 Batch 0500/1563 - Loss: 0.1391
2025-09-10 18:13:10,994 - INFO - Epoch 017 Batch 0600/1563 - Loss: 0.1058
2025-09-10 18:13:12,592 - INFO - Epoch 017 Batch 0700/1563 - Loss: 0.2265
2025-09-10 18:13:14,210 - INFO - Epoch 017 Batch 0800/1563 - Loss: 0.1790
2025-09-10 18:13:15,800 - INFO - Epoch 017 Batch 0900/1563 - Loss: 0.4682
2025-09-10 18:13:17,416 - INFO - Epoch 017 Batch 1000/1563 - Loss: 0.0850
2025-09-10 18:13:18,999 - INFO - Epoch 017 Batch 1100/1563 - Loss: 0.0794
2025-09-10 18:13:20,607 - INFO - Epoch 017 Batch 1200/1563 - Loss: 0.2638
2025-09-10 18:13:22,219 - INFO - Epoch 017 Batch 1300/1563 - Loss: 0.1773
2025-09-10 18:13:23,821 - INFO - Epoch 017 Batch 1400/1563 - Loss: 0.3005
2025-09-10 18:13:25,437 - INFO - Epoch 017 Batch 1500/1563 - Loss: 0.2300
2025-09-10 18:13:26,446 - INFO - Epoch 017: Train Loss = 0.1670
2025-09-10 18:13:28,096 - INFO - Epoch 018 Batch 0100/1563 - Loss: 0.0624
2025-09-10 18:13:29,743 - INFO - Epoch 018 Batch 0200/1563 - Loss: 0.0904
2025-09-10 18:13:31,359 - INFO - Epoch 018 Batch 0300/1563 - Loss: 0.2381
2025-09-10 18:13:33,002 - INFO - Epoch 018 Batch 0400/1563 - Loss: 0.1080
2025-09-10 18:13:34,628 - INFO - Epoch 018 Batch 0500/1563 - Loss: 0.0517
2025-09-10 18:13:36,249 - INFO - Epoch 018 Batch 0600/1563 - Loss: 0.1723
2025-09-10 18:13:37,871 - INFO - Epoch 018 Batch 0700/1563 - Loss: 0.1053
2025-09-10 18:13:39,491 - INFO - Epoch 018 Batch 0800/1563 - Loss: 0.1095
2025-09-10 18:19:29,136 - INFO - Epoch 001 Batch 0100/1563 - Loss: 2.2354
2025-09-10 18:19:30,772 - INFO - Epoch 001 Batch 0200/1563 - Loss: 2.0586
2025-09-10 18:19:32,425 - INFO - Epoch 001 Batch 0300/1563 - Loss: 2.0766
2025-09-10 18:19:34,072 - INFO - Epoch 001 Batch 0400/1563 - Loss: 2.0225
2025-09-10 18:19:35,698 - INFO - Epoch 001 Batch 0500/1563 - Loss: 1.6713
2025-09-10 18:19:37,389 - INFO - Epoch 001 Batch 0600/1563 - Loss: 1.6911
2025-09-10 18:19:38,980 - INFO - Epoch 001 Batch 0700/1563 - Loss: 1.7608
2025-09-10 18:19:40,589 - INFO - Epoch 001 Batch 0800/1563 - Loss: 1.2519
2025-09-10 18:19:42,207 - INFO - Epoch 001 Batch 0900/1563 - Loss: 1.8223
2025-09-10 18:19:43,821 - INFO - Epoch 001 Batch 1000/1563 - Loss: 1.5003
2025-09-10 18:19:45,400 - INFO - Epoch 001 Batch 1100/1563 - Loss: 1.6551
2025-09-10 18:19:46,980 - INFO - Epoch 001 Batch 1200/1563 - Loss: 1.7478
2025-09-10 18:19:48,611 - INFO - Epoch 001 Batch 1300/1563 - Loss: 1.7063
2025-09-10 18:19:50,201 - INFO - Epoch 001 Batch 1400/1563 - Loss: 1.2902
2025-09-10 18:19:51,822 - INFO - Epoch 001 Batch 1500/1563 - Loss: 1.7851
2025-09-10 18:19:52,842 - INFO - Epoch 001: Train Loss = 1.7278
2025-09-10 18:19:54,424 - INFO - Epoch 002 Batch 0100/1563 - Loss: 1.4394
2025-09-10 18:19:56,032 - INFO - Epoch 002 Batch 0200/1563 - Loss: 1.5965
2025-09-10 18:19:57,617 - INFO - Epoch 002 Batch 0300/1563 - Loss: 1.4225
2025-09-10 18:19:59,200 - INFO - Epoch 002 Batch 0400/1563 - Loss: 1.6390
2025-09-10 18:20:00,800 - INFO - Epoch 002 Batch 0500/1563 - Loss: 1.0348
2025-09-10 18:20:02,429 - INFO - Epoch 002 Batch 0600/1563 - Loss: 1.2871
2025-09-10 18:20:04,059 - INFO - Epoch 002 Batch 0700/1563 - Loss: 1.2143
2025-09-10 18:20:05,652 - INFO - Epoch 002 Batch 0800/1563 - Loss: 1.3855
2025-09-10 18:20:07,245 - INFO - Epoch 002 Batch 0900/1563 - Loss: 1.0247
2025-09-10 18:20:08,852 - INFO - Epoch 002 Batch 1000/1563 - Loss: 1.5540
2025-09-10 18:20:10,430 - INFO - Epoch 002 Batch 1100/1563 - Loss: 1.1833
2025-09-10 18:20:12,051 - INFO - Epoch 002 Batch 1200/1563 - Loss: 1.3951
2025-09-10 18:20:13,672 - INFO - Epoch 002 Batch 1300/1563 - Loss: 1.3347
2025-09-10 18:20:15,460 - INFO - Epoch 002 Batch 1400/1563 - Loss: 1.1617
2025-09-10 18:20:17,813 - INFO - Epoch 002 Batch 1500/1563 - Loss: 1.2520
2025-09-10 18:20:18,877 - INFO - Epoch 002: Train Loss = 1.3485
2025-09-10 18:20:20,571 - INFO - Epoch 003 Batch 0100/1563 - Loss: 0.8372
2025-09-10 18:20:22,230 - INFO - Epoch 003 Batch 0200/1563 - Loss: 1.1817
2025-09-10 18:20:23,862 - INFO - Epoch 003 Batch 0300/1563 - Loss: 1.0719
2025-09-10 18:20:25,479 - INFO - Epoch 003 Batch 0400/1563 - Loss: 1.5063
2025-09-10 18:20:27,098 - INFO - Epoch 003 Batch 0500/1563 - Loss: 1.1077
2025-09-10 18:20:28,716 - INFO - Epoch 003 Batch 0600/1563 - Loss: 1.0988
2025-09-10 18:20:30,326 - INFO - Epoch 003 Batch 0700/1563 - Loss: 0.9588
2025-09-10 18:20:31,946 - INFO - Epoch 003 Batch 0800/1563 - Loss: 1.2651
2025-09-10 18:20:33,570 - INFO - Epoch 003 Batch 0900/1563 - Loss: 1.1709
2025-09-10 18:20:35,204 - INFO - Epoch 003 Batch 1000/1563 - Loss: 1.2272
2025-09-10 18:20:36,839 - INFO - Epoch 003 Batch 1100/1563 - Loss: 1.1716
2025-09-10 18:20:38,462 - INFO - Epoch 003 Batch 1200/1563 - Loss: 1.2691
2025-09-10 18:20:40,103 - INFO - Epoch 003 Batch 1300/1563 - Loss: 0.8965
2025-09-10 18:20:41,771 - INFO - Epoch 003 Batch 1400/1563 - Loss: 1.1842
2025-09-10 18:20:43,433 - INFO - Epoch 003 Batch 1500/1563 - Loss: 1.1761
2025-09-10 18:20:44,448 - INFO - Epoch 003: Train Loss = 1.1780
2025-09-10 18:20:46,107 - INFO - Epoch 004 Batch 0100/1563 - Loss: 0.9382
2025-09-10 18:20:47,840 - INFO - Epoch 004 Batch 0200/1563 - Loss: 0.9417
2025-09-10 18:20:49,512 - INFO - Epoch 004 Batch 0300/1563 - Loss: 0.8522
2025-09-10 18:20:51,136 - INFO - Epoch 004 Batch 0400/1563 - Loss: 1.1373
2025-09-10 18:20:54,186 - INFO - Epoch 004 Batch 0500/1563 - Loss: 1.0669
2025-09-10 18:20:58,263 - INFO - Epoch 004 Batch 0600/1563 - Loss: 1.0836
2025-09-10 18:21:01,789 - INFO - Epoch 004 Batch 0700/1563 - Loss: 0.9159
2025-09-10 18:21:05,212 - INFO - Epoch 004 Batch 0800/1563 - Loss: 1.1042
2025-09-10 18:21:09,282 - INFO - Epoch 004 Batch 0900/1563 - Loss: 1.2024
2025-09-10 18:21:11,702 - INFO - Epoch 004 Batch 1000/1563 - Loss: 1.0665
2025-09-10 18:21:13,327 - INFO - Epoch 004 Batch 1100/1563 - Loss: 1.2684
2025-09-10 18:21:14,961 - INFO - Epoch 004 Batch 1200/1563 - Loss: 1.3865
2025-09-10 18:21:16,599 - INFO - Epoch 004 Batch 1300/1563 - Loss: 1.0850
2025-09-10 18:21:18,205 - INFO - Epoch 004 Batch 1400/1563 - Loss: 0.9461
2025-09-10 18:21:19,844 - INFO - Epoch 004 Batch 1500/1563 - Loss: 1.0414
2025-09-10 18:21:20,910 - INFO - Epoch 004: Train Loss = 1.0540
2025-09-10 18:21:22,581 - INFO - Epoch 005 Batch 0100/1563 - Loss: 1.0567
2025-09-10 18:21:24,229 - INFO - Epoch 005 Batch 0200/1563 - Loss: 1.0460
2025-09-10 18:21:25,854 - INFO - Epoch 005 Batch 0300/1563 - Loss: 0.9586
2025-09-10 18:21:27,512 - INFO - Epoch 005 Batch 0400/1563 - Loss: 0.8698
2025-09-10 18:21:29,112 - INFO - Epoch 005 Batch 0500/1563 - Loss: 0.7747
2025-09-10 18:21:30,727 - INFO - Epoch 005 Batch 0600/1563 - Loss: 1.1456
2025-09-10 18:21:32,334 - INFO - Epoch 005 Batch 0700/1563 - Loss: 0.9526
2025-09-10 18:21:33,964 - INFO - Epoch 005 Batch 0800/1563 - Loss: 0.7674
2025-09-10 18:21:35,582 - INFO - Epoch 005 Batch 0900/1563 - Loss: 0.9141
2025-09-10 18:21:37,194 - INFO - Epoch 005 Batch 1000/1563 - Loss: 0.9715
2025-09-10 18:21:38,786 - INFO - Epoch 005 Batch 1100/1563 - Loss: 1.2158
2025-09-10 18:21:40,387 - INFO - Epoch 005 Batch 1200/1563 - Loss: 0.9134
2025-09-10 18:21:41,997 - INFO - Epoch 005 Batch 1300/1563 - Loss: 0.8912
2025-09-10 18:21:43,622 - INFO - Epoch 005 Batch 1400/1563 - Loss: 0.7441
2025-09-10 18:21:45,253 - INFO - Epoch 005 Batch 1500/1563 - Loss: 0.7356
2025-09-10 18:21:46,271 - INFO - Epoch 005: Train Loss = 0.9522
2025-09-10 18:21:47,889 - INFO - Epoch 006 Batch 0100/1563 - Loss: 0.9563
2025-09-10 18:21:49,513 - INFO - Epoch 006 Batch 0200/1563 - Loss: 1.0144
2025-09-10 18:21:51,137 - INFO - Epoch 006 Batch 0300/1563 - Loss: 1.0998
2025-09-10 18:21:52,792 - INFO - Epoch 006 Batch 0400/1563 - Loss: 0.7267
2025-09-10 18:21:54,449 - INFO - Epoch 006 Batch 0500/1563 - Loss: 0.7149
2025-09-10 18:21:56,071 - INFO - Epoch 006 Batch 0600/1563 - Loss: 0.9057
2025-09-10 18:21:57,670 - INFO - Epoch 006 Batch 0700/1563 - Loss: 0.9227
2025-09-10 18:21:59,330 - INFO - Epoch 006 Batch 0800/1563 - Loss: 0.7428
2025-09-10 18:22:01,012 - INFO - Epoch 006 Batch 0900/1563 - Loss: 1.0353
2025-09-10 18:22:02,648 - INFO - Epoch 006 Batch 1000/1563 - Loss: 0.4085
2025-09-10 18:22:04,290 - INFO - Epoch 006 Batch 1100/1563 - Loss: 1.2631
2025-09-10 18:22:05,926 - INFO - Epoch 006 Batch 1200/1563 - Loss: 0.7840
2025-09-10 18:22:07,543 - INFO - Epoch 006 Batch 1300/1563 - Loss: 1.1677
2025-09-10 18:22:09,167 - INFO - Epoch 006 Batch 1400/1563 - Loss: 0.9689
2025-09-10 18:22:10,803 - INFO - Epoch 006 Batch 1500/1563 - Loss: 0.8792
2025-09-10 18:22:11,824 - INFO - Epoch 006: Train Loss = 0.8629
2025-09-10 18:22:13,443 - INFO - Epoch 007 Batch 0100/1563 - Loss: 0.7504
2025-09-10 18:22:15,081 - INFO - Epoch 007 Batch 0200/1563 - Loss: 0.6161
2025-09-10 18:22:16,724 - INFO - Epoch 007 Batch 0300/1563 - Loss: 0.7970
2025-09-10 18:22:18,348 - INFO - Epoch 007 Batch 0400/1563 - Loss: 0.8379
2025-09-10 18:22:19,974 - INFO - Epoch 007 Batch 0500/1563 - Loss: 1.1333
2025-09-10 18:22:21,610 - INFO - Epoch 007 Batch 0600/1563 - Loss: 0.7071
2025-09-10 18:22:23,252 - INFO - Epoch 007 Batch 0700/1563 - Loss: 1.0458
2025-09-10 18:22:24,872 - INFO - Epoch 007 Batch 0800/1563 - Loss: 0.6531
2025-09-10 18:22:26,517 - INFO - Epoch 007 Batch 0900/1563 - Loss: 0.9178
2025-09-10 18:22:28,174 - INFO - Epoch 007 Batch 1000/1563 - Loss: 1.7829
2025-09-10 18:22:29,816 - INFO - Epoch 007 Batch 1100/1563 - Loss: 0.8430
2025-09-10 18:22:31,482 - INFO - Epoch 007 Batch 1200/1563 - Loss: 0.6616
2025-09-10 18:22:33,156 - INFO - Epoch 007 Batch 1300/1563 - Loss: 0.3588
2025-09-10 18:22:34,774 - INFO - Epoch 007 Batch 1400/1563 - Loss: 0.8389
2025-09-10 18:22:36,410 - INFO - Epoch 007 Batch 1500/1563 - Loss: 0.4701
2025-09-10 18:22:37,447 - INFO - Epoch 007: Train Loss = 0.7865
2025-09-10 18:22:39,095 - INFO - Epoch 008 Batch 0100/1563 - Loss: 0.7423
2025-09-10 18:22:40,747 - INFO - Epoch 008 Batch 0200/1563 - Loss: 0.5678
2025-09-10 18:22:42,409 - INFO - Epoch 008 Batch 0300/1563 - Loss: 0.5995
2025-09-10 18:22:44,055 - INFO - Epoch 008 Batch 0400/1563 - Loss: 0.8476
2025-09-10 18:22:45,724 - INFO - Epoch 008 Batch 0500/1563 - Loss: 0.5801
2025-09-10 18:22:47,352 - INFO - Epoch 008 Batch 0600/1563 - Loss: 0.8816
2025-09-10 18:22:48,978 - INFO - Epoch 008 Batch 0700/1563 - Loss: 0.7220
2025-09-10 18:22:50,599 - INFO - Epoch 008 Batch 0800/1563 - Loss: 1.0118
2025-09-10 18:22:52,174 - INFO - Epoch 008 Batch 0900/1563 - Loss: 0.7899
2025-09-10 18:22:53,810 - INFO - Epoch 008 Batch 1000/1563 - Loss: 1.0816
2025-09-10 18:22:55,417 - INFO - Epoch 008 Batch 1100/1563 - Loss: 0.6392
2025-09-10 18:22:57,039 - INFO - Epoch 008 Batch 1200/1563 - Loss: 0.8131
2025-09-10 18:22:58,663 - INFO - Epoch 008 Batch 1300/1563 - Loss: 0.6078
2025-09-10 18:23:00,284 - INFO - Epoch 008 Batch 1400/1563 - Loss: 0.4865
2025-09-10 18:23:01,916 - INFO - Epoch 008 Batch 1500/1563 - Loss: 0.8495
2025-09-10 18:23:02,938 - INFO - Epoch 008: Train Loss = 0.7130
2025-09-10 18:23:04,535 - INFO - Epoch 009 Batch 0100/1563 - Loss: 0.5074
2025-09-10 18:23:06,109 - INFO - Epoch 009 Batch 0200/1563 - Loss: 0.5494
2025-09-10 18:23:07,689 - INFO - Epoch 009 Batch 0300/1563 - Loss: 0.5534
2025-09-10 18:23:09,289 - INFO - Epoch 009 Batch 0400/1563 - Loss: 0.3716
2025-09-10 18:23:10,880 - INFO - Epoch 009 Batch 0500/1563 - Loss: 0.4969
2025-09-10 18:23:12,482 - INFO - Epoch 009 Batch 0600/1563 - Loss: 0.3203
2025-09-10 18:23:14,039 - INFO - Epoch 009 Batch 0700/1563 - Loss: 0.4906
2025-09-10 18:23:15,657 - INFO - Epoch 009 Batch 0800/1563 - Loss: 0.6266
2025-09-10 18:23:17,279 - INFO - Epoch 009 Batch 0900/1563 - Loss: 0.8809
2025-09-10 18:23:18,865 - INFO - Epoch 009 Batch 1000/1563 - Loss: 0.4390
2025-09-10 18:23:20,443 - INFO - Epoch 009 Batch 1100/1563 - Loss: 0.7216
2025-09-10 18:23:22,048 - INFO - Epoch 009 Batch 1200/1563 - Loss: 0.8495
2025-09-10 18:23:23,649 - INFO - Epoch 009 Batch 1300/1563 - Loss: 0.8770
2025-09-10 18:23:25,259 - INFO - Epoch 009 Batch 1400/1563 - Loss: 0.8747
2025-09-10 18:23:26,859 - INFO - Epoch 009 Batch 1500/1563 - Loss: 0.4474
2025-09-10 18:23:27,826 - INFO - Epoch 009: Train Loss = 0.6480
2025-09-10 18:23:29,407 - INFO - Epoch 010 Batch 0100/1563 - Loss: 0.4279
2025-09-10 18:23:31,006 - INFO - Epoch 010 Batch 0200/1563 - Loss: 0.6209
2025-09-10 18:23:32,621 - INFO - Epoch 010 Batch 0300/1563 - Loss: 0.4136
2025-09-10 18:23:34,211 - INFO - Epoch 010 Batch 0400/1563 - Loss: 0.8492
2025-09-10 18:23:35,835 - INFO - Epoch 010 Batch 0500/1563 - Loss: 0.6024
2025-09-10 18:23:37,448 - INFO - Epoch 010 Batch 0600/1563 - Loss: 0.4480
2025-09-10 18:23:39,058 - INFO - Epoch 010 Batch 0700/1563 - Loss: 0.8408
2025-09-10 18:23:40,635 - INFO - Epoch 010 Batch 0800/1563 - Loss: 0.6578
2025-09-10 18:23:42,246 - INFO - Epoch 010 Batch 0900/1563 - Loss: 0.6993
2025-09-10 18:23:43,865 - INFO - Epoch 010 Batch 1000/1563 - Loss: 0.5105
2025-09-10 18:23:45,483 - INFO - Epoch 010 Batch 1100/1563 - Loss: 0.5838
2025-09-10 18:23:47,086 - INFO - Epoch 010 Batch 1200/1563 - Loss: 0.5259
2025-09-10 18:23:48,718 - INFO - Epoch 010 Batch 1300/1563 - Loss: 0.7964
2025-09-10 18:23:50,294 - INFO - Epoch 010 Batch 1400/1563 - Loss: 0.5101
2025-09-10 18:23:51,889 - INFO - Epoch 010 Batch 1500/1563 - Loss: 0.7445
2025-09-10 18:23:52,896 - INFO - Epoch 010: Train Loss = 0.5806
2025-09-10 18:23:55,795 - INFO - Test Loss: 0.9004 | Test Accuracy: 69.82%
2025-09-10 18:23:57,368 - INFO - Epoch 011 Batch 0100/1563 - Loss: 0.8258
2025-09-10 18:23:58,971 - INFO - Epoch 011 Batch 0200/1563 - Loss: 0.5843
2025-09-10 18:24:00,553 - INFO - Epoch 011 Batch 0300/1563 - Loss: 0.5818
2025-09-10 18:24:02,110 - INFO - Epoch 011 Batch 0400/1563 - Loss: 0.8929
2025-09-10 18:24:03,687 - INFO - Epoch 011 Batch 0500/1563 - Loss: 0.3467
2025-09-10 18:24:05,293 - INFO - Epoch 011 Batch 0600/1563 - Loss: 0.3838
2025-09-10 18:24:06,882 - INFO - Epoch 011 Batch 0700/1563 - Loss: 0.3245
2025-09-10 18:24:08,497 - INFO - Epoch 011 Batch 0800/1563 - Loss: 0.6540
2025-09-10 18:24:10,086 - INFO - Epoch 011 Batch 0900/1563 - Loss: 0.3633
2025-09-10 18:24:11,676 - INFO - Epoch 011 Batch 1000/1563 - Loss: 0.5132
2025-09-10 18:24:13,228 - INFO - Epoch 011 Batch 1100/1563 - Loss: 0.4212
2025-09-10 18:24:14,771 - INFO - Epoch 011 Batch 1200/1563 - Loss: 0.3498
2025-09-10 18:24:16,357 - INFO - Epoch 011 Batch 1300/1563 - Loss: 0.4939
2025-09-10 18:24:17,939 - INFO - Epoch 011 Batch 1400/1563 - Loss: 0.5196
2025-09-10 18:24:19,531 - INFO - Epoch 011 Batch 1500/1563 - Loss: 0.6533
2025-09-10 18:24:20,519 - INFO - Epoch 011: Train Loss = 0.5191
2025-09-10 18:24:22,082 - INFO - Epoch 012 Batch 0100/1563 - Loss: 0.4720
2025-09-10 18:24:23,632 - INFO - Epoch 012 Batch 0200/1563 - Loss: 0.3257
2025-09-10 18:24:25,159 - INFO - Epoch 012 Batch 0300/1563 - Loss: 0.4258
2025-09-10 18:24:26,734 - INFO - Epoch 012 Batch 0400/1563 - Loss: 0.3333
2025-09-10 18:24:28,329 - INFO - Epoch 012 Batch 0500/1563 - Loss: 0.4498
2025-09-10 18:24:29,908 - INFO - Epoch 012 Batch 0600/1563 - Loss: 0.3278
2025-09-10 18:24:31,472 - INFO - Epoch 012 Batch 0700/1563 - Loss: 0.3934
2025-09-10 18:24:33,014 - INFO - Epoch 012 Batch 0800/1563 - Loss: 0.8632
2025-09-10 18:24:34,573 - INFO - Epoch 012 Batch 0900/1563 - Loss: 0.2798
2025-09-10 18:24:36,137 - INFO - Epoch 012 Batch 1000/1563 - Loss: 0.7437
2025-09-10 18:24:37,720 - INFO - Epoch 012 Batch 1100/1563 - Loss: 0.3019
2025-09-10 18:24:39,280 - INFO - Epoch 012 Batch 1200/1563 - Loss: 0.4889
2025-09-10 18:24:40,842 - INFO - Epoch 012 Batch 1300/1563 - Loss: 0.4216
2025-09-10 18:24:42,446 - INFO - Epoch 012 Batch 1400/1563 - Loss: 0.5645
2025-09-10 18:24:44,015 - INFO - Epoch 012 Batch 1500/1563 - Loss: 0.4276
2025-09-10 18:24:44,967 - INFO - Epoch 012: Train Loss = 0.4559
2025-09-10 18:24:47,745 - INFO - Test Loss: 0.9158 | Test Accuracy: 70.30%
